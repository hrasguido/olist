# ğŸ›ï¸ Olist E-Commerce - PredicciÃ³n de Retrasos en Entregas

## ğŸ“‹ DescripciÃ³n del Proyecto

Sistema de anÃ¡lisis y predicciÃ³n de retrasos en entregas para Olist, el marketplace brasileÃ±o mÃ¡s grande. Este proyecto implementa un pipeline completo de ETL y Machine Learning para predecir el tiempo de retraso (`Delayed_time`) en las entregas de pedidos.

### ğŸ¯ Objetivo

Predecir el tiempo de retraso en dÃ­as entre la fecha estimada de entrega y la fecha real de entrega, utilizando mÃºltiples algoritmos de Machine Learning con validaciÃ³n cruzada.

### ğŸ—ï¸ Arquitectura del Proyecto

```
Bronze (Raw Data) â†’ Silver (Curated) â†’ Gold (Analytics & ML)
```

- **Bronze**: Datos crudos desde archivos CSV
- **Silver**: Datos limpios y normalizados
- **Gold**: Master table con features engineered + Modelos ML

---

## ğŸ“ Estructura del Proyecto

```
olist/
â”œâ”€â”€ data/                           # Datos CSV originales
â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”œâ”€â”€ olist_orders_dataset.csv
â”‚   â”œâ”€â”€ olist_order_items_dataset.csv
â”‚   â”œâ”€â”€ olist_products_dataset.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                            # CÃ³digo fuente
â”‚   â”œâ”€â”€ bronze_to_raw.py           # ETL: CSV â†’ PostgreSQL (Bronze)
â”‚   â”œâ”€â”€ silver_curated.py          # ETL: Bronze â†’ Silver (Limpieza)
â”‚   â”œâ”€â”€ gold_fact_sales.py         # ETL: Silver â†’ Gold (ML Pipeline)
â”‚   â”œâ”€â”€ gold_features.py           # Feature Engineering
â”‚   â”œâ”€â”€ model_evaluation.py        # EvaluaciÃ³n con Cross-Validation
â”‚   â”œâ”€â”€ flow.py                    # OrquestaciÃ³n Prefect
â”‚   â””â”€â”€ conn.py                    # ConfiguraciÃ³n de conexiones
â”œâ”€â”€ requirements.txt               # Dependencias Python
â”œâ”€â”€ docker-compose.yml             # ConfiguraciÃ³n Docker
â”œâ”€â”€ .env                          # Variables de entorno
â””â”€â”€ README.md                     # Este archivo
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Docker y Docker Compose
- Python 3.9+
- PostgreSQL (via Docker)

### Paso 1: Clonar el Repositorio

```bash
git clone <repository-url>
cd olist
```

### Paso 2: Configurar Variables de Entorno

Crea un archivo `.env` en la raÃ­z del proyecto:

```env
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres
POSTGRES_HOST=db
POSTGRES_PORT=5432
```

### Paso 3: Levantar Servicios con Docker

```bash
docker-compose up -d
```

Esto iniciarÃ¡:
- PostgreSQL (puerto 5432)
- Prefect Server (puerto 4200)
- Jupyter Notebook (opcional, puerto 8888)

### Paso 4: Instalar Dependencias Python

```bash
pip install -r requirements.txt
```

**Dependencias principales:**
- `prefect==2.18.1` - OrquestaciÃ³n de workflows
- `pandas==2.2.2` - ManipulaciÃ³n de datos
- `scikit-learn==1.7.2` - Machine Learning
- `xgboost==3.1.1` - Gradient Boosting
- `optuna==3.5.0` - OptimizaciÃ³n de hiperparÃ¡metros
- `sqlalchemy==2.0.35` - ORM para PostgreSQL
- `psycopg2-binary==2.9.9` - Driver PostgreSQL

---

## ğŸ”„ Pipeline de EjecuciÃ³n

### Flujo Completo

```bash
# Ejecutar pipeline completo (Bronze â†’ Silver â†’ Gold)
cd src
python flow.py
```

### EjecuciÃ³n por Capas

#### 1ï¸âƒ£ Bronze Layer (CSV â†’ PostgreSQL)

```bash
python bronze_to_raw.py
```

**QuÃ© hace:**
- Carga datos desde archivos CSV
- Crea base de datos `bronze` en PostgreSQL
- Guarda datos crudos en esquema `raw`

**Tablas creadas:**
- `bronze.raw.customers`
- `bronze.raw.orders`
- `bronze.raw.order_items`
- `bronze.raw.products`
- `bronze.raw.sellers`
- `bronze.raw.order_payments`
- `bronze.raw.order_reviews`
- `bronze.raw.geolocation`
- `bronze.raw.product_category_translation`

#### 2ï¸âƒ£ Silver Layer (Limpieza y NormalizaciÃ³n)

```bash
python silver_curated.py
```

**QuÃ© hace:**
- Lee datos desde Bronze
- Limpia valores nulos y duplicados
- Normaliza tipos de datos
- Valida integridad referencial
- Guarda en base de datos `silver` esquema `curated`

**Transformaciones:**
- ConversiÃ³n de fechas a formato datetime
- NormalizaciÃ³n de cÃ³digos postales
- Limpieza de valores nulos
- ValidaciÃ³n de foreign keys

#### 3ï¸âƒ£ Gold Layer (Feature Engineering + ML)

```bash
python gold_fact_sales.py
```

**QuÃ© hace:**

1. **ConstrucciÃ³n de Master Table**
   - Join de todas las tablas relacionadas
   - Filtrado de Ã³rdenes entregadas (`order_status = 'delivered'`)
   - CÃ¡lculo del target: `Delayed_time = order_delivered_customer_date - order_estimated_delivery_date`
   - EliminaciÃ³n de duplicados y outliers

2. **One-Hot Encoding**
   - CodificaciÃ³n de variables categÃ³ricas:
     - `product_category_name`
     - `payment_type`
     - `customer_state`
     - `seller_state`

3. **Feature Selection**
   - **MÃ©todo 1**: CorrelaciÃ³n de Pearson
   - **MÃ©todo 2**: Mutual Information
   - **MÃ©todo 3**: Random Forest Feature Importance
   - SelecciÃ³n de top 50 features mÃ¡s relevantes

4. **ğŸ†• EvaluaciÃ³n con ValidaciÃ³n Cruzada**
   - ComparaciÃ³n de 6 modelos:
     - Linear Regression
     - Ridge Regression
     - Lasso Regression
     - Random Forest
     - Gradient Boosting
     - XGBoost
   - K-Fold Cross-Validation (5 folds)
   - MÃ©tricas: MAE, RMSE, RÂ²
   - AnÃ¡lisis de overfitting
   - Ranking general de modelos

5. **Entrenamiento del Modelo Final (XGBoost)**
   - OptimizaciÃ³n de hiperparÃ¡metros con Optuna (50 trials)
   - Split: 60% train, 20% validation, 20% test
   - MÃ©tricas en train y test
   - Feature importance

6. **ğŸ’¾ ExportaciÃ³n del Modelo**
   - Guardado en formato pickle (`.pkl`)
   - Incluye: modelo + mÃ©tricas + features + metadata
   - UbicaciÃ³n: `/workspace/xgboost_model_final.pkl`

7. **Feature Engineering Avanzado**
   - Features temporales (dÃ­a, mes, aÃ±o, dÃ­a de semana)
   - Features logÃ­sticas (distancias, tiempos de envÃ­o)
   - Features de pago (mÃ©todos, cuotas, valores)
   - Features de cliente (recurrencia, comportamiento)

**Tablas creadas en Gold:**
- `gold.dm.master_table` - Tabla principal con predicciones
- `gold.dm.features` - Features completas para anÃ¡lisis
- `gold.dm.geolocation` - GeolocalizaciÃ³n sin duplicados

---

## ğŸ“Š EvaluaciÃ³n de Modelos

### Modelos Comparados

| Modelo | DescripciÃ³n | Uso |
|--------|-------------|-----|
| **Linear Regression** | RegresiÃ³n lineal simple | Baseline |
| **Ridge Regression** | RegresiÃ³n con regularizaciÃ³n L2 | Control de overfitting |
| **Lasso Regression** | RegresiÃ³n con regularizaciÃ³n L1 | Feature selection |
| **Random Forest** | Ensemble de Ã¡rboles de decisiÃ³n | Robusto a outliers |
| **Gradient Boosting** | Boosting secuencial | Alta precisiÃ³n |
| **XGBoost** | Gradient boosting optimizado | Mejor performance |

### MÃ©tricas de EvaluaciÃ³n

- **MAE (Mean Absolute Error)**: Error promedio en dÃ­as
- **RMSE (Root Mean Squared Error)**: Penaliza errores grandes
- **RÂ² (Coefficient of Determination)**: Varianza explicada (0-1)
- **Training Time**: Tiempo de entrenamiento

### ValidaciÃ³n Cruzada

- **MÃ©todo**: K-Fold Cross-Validation (5 folds)
- **Ventajas**:
  - Reduce overfitting
  - EstimaciÃ³n mÃ¡s robusta del rendimiento
  - Utiliza todos los datos para train y test

### Resultados Exportados

Los resultados se guardan en:
```
/workspace/model_comparison_results.csv
```

Columnas:
- `model_name`: Nombre del modelo
- `test_mae_mean`, `test_mae_std`: MAE en test Â± desviaciÃ³n
- `test_rmse_mean`, `test_rmse_std`: RMSE en test Â± desviaciÃ³n
- `test_r2_mean`, `test_r2_std`: RÂ² en test Â± desviaciÃ³n
- `train_mae_mean`, `train_r2_mean`: MÃ©tricas en train
- `fit_time_mean`: Tiempo de entrenamiento
- `overall_score`: Score general (0-1)

---

## ğŸ¤– Uso del Modelo Guardado

### Cargar el Modelo

```python
import pickle
import pandas as pd

# Cargar modelo
with open('/workspace/xgboost_model_final.pkl', 'rb') as f:
    model_package = pickle.load(f)

# Extraer componentes
model = model_package['model']
features = model_package['feature_columns']
metrics = model_package['metrics']

print(f"Modelo: {model_package['model_type']}")
print(f"Features: {len(features)}")
print(f"Test MAE: {metrics['test']['mae']:.3f} dÃ­as")
print(f"Test RÂ²: {metrics['test']['r2']:.4f}")
```

### Hacer Predicciones

```python
# Cargar nuevos datos
new_data = pd.read_csv('new_orders.csv')

# Asegurarse de tener las mismas features
X_new = new_data[features].fillna(0)

# Predecir
predictions = model.predict(X_new)

# Interpretar
new_data['predicted_delay'] = predictions
print(new_data[['order_id', 'predicted_delay']].head())
```

### Ejemplo Completo

```python
def predict_delivery_delay(order_data: pd.DataFrame) -> pd.DataFrame:
    """
    Predice el retraso en dÃ­as para nuevos pedidos.
    
    Args:
        order_data: DataFrame con datos del pedido
    
    Returns:
        DataFrame con predicciones
    """
    # Cargar modelo
    with open('/workspace/xgboost_model_final.pkl', 'rb') as f:
        model_package = pickle.load(f)
    
    model = model_package['model']
    features = model_package['feature_columns']
    
    # Preparar datos
    X = order_data[features].fillna(0)
    
    # Predecir
    predictions = model.predict(X)
    
    # Agregar al DataFrame
    order_data['predicted_delay_days'] = predictions
    order_data['delay_category'] = pd.cut(
        predictions,
        bins=[-float('inf'), -5, 0, 5, float('inf')],
        labels=['Muy Adelantado', 'A Tiempo', 'Leve Retraso', 'Retraso Grave']
    )
    
    return order_data

# Uso
new_orders = pd.read_csv('new_orders.csv')
results = predict_delivery_delay(new_orders)
print(results[['order_id', 'predicted_delay_days', 'delay_category']])
```

---

## ğŸ“ˆ Monitoreo y Logs

### Prefect UI

Accede a la interfaz de Prefect para monitorear ejecuciones:

```bash
# Iniciar Prefect Server
prefect server start

# Abrir en navegador
http://localhost:4200
```

### Logs del Pipeline

Los logs se imprimen en consola con formato detallado:

```
ğŸ¥‡ INICIANDO CONSTRUCCIÃ“N DE MASTER TABLE + EVALUACIÃ“N DE MODELOS
================================================================================
ğŸ“¥ Cargando datasets desde Silver...
   âœ… customers: 99,441 registros
   âœ… orders: 99,441 registros
...
ğŸ† COMPARACIÃ“N DE MODELOS CON VALIDACIÃ“N CRUZADA
================================================================================
   ğŸ”„ Evaluando Linear Regression con 5-Fold CV...
      âœ… Test MAE: 8.234 Â± 0.123
      âœ… Test RMSE: 10.567 Â± 0.234
      âœ… Test RÂ²: 0.4567 Â± 0.0234
...
ğŸ† Mejor modelo identificado: XGBoost
   - Test MAE promedio: 7.123 dÃ­as
   - Features utilizadas: 50
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Ajustar HiperparÃ¡metros de Optuna

En [gold_fact_sales.py](cci:7://file:///Users/howard/Downloads/modulo13/sprint3/olist/src/gold_fact_sales.py:0:0-0:0), lÃ­nea ~960:

```python
xgb_result = train_xgboost_model(
    master_df, 
    target_col='Delayed_time',
    use_optuna=True,
    n_trials=100  # Aumentar para mejor optimizaciÃ³n (mÃ¡s lento)
)
```

### Cambiar NÃºmero de Folds en CV

En [gold_fact_sales.py](cci:7://file:///Users/howard/Downloads/modulo13/sprint3/olist/src/gold_fact_sales.py:0:0-0:0), lÃ­nea ~890:

```python
cv_results = evaluate_models_with_cv(
    master_df,
    target_col='Delayed_time',
    cv_folds=10,  # Aumentar para validaciÃ³n mÃ¡s robusta
    save_results=True
)
```

### Modificar Feature Selection

En [gold_fact_sales.py](cci:7://file:///Users/howard/Downloads/modulo13/sprint3/olist/src/gold_fact_sales.py:0:0-0:0), lÃ­nea ~950:

```python
master_df = feature_selection(
    master_df, 
    target_col='Delayed_time',
    correlation_threshold=0.03,  # MÃ¡s bajo = mÃ¡s features
    top_n_features=100  # Aumentar para mÃ¡s features
)
```

---

## ğŸ“Š AnÃ¡lisis de Resultados

### Consultas SQL Ãštiles

```sql
-- Ver estadÃ­sticas de retrasos
SELECT 
    AVG(Delayed_time) as avg_delay,
    STDDEV(Delayed_time) as std_delay,
    MIN(Delayed_time) as min_delay,
    MAX(Delayed_time) as max_delay
FROM gold.dm.master_table;

-- Comparar predicciÃ³n vs real
SELECT 
    order_id,
    Delayed_time as real_delay,
    Delayed_time_predicted as predicted_delay,
    prediction_error_abs as error
FROM gold.dm.master_table
ORDER BY prediction_error_abs DESC
LIMIT 10;

-- AnÃ¡lisis por categorÃ­a de producto
SELECT 
    product_category_name,
    COUNT(*) as orders,
    AVG(Delayed_time) as avg_delay,
    AVG(Delayed_time_predicted) as avg_predicted
FROM gold.dm.master_table
GROUP BY product_category_name
ORDER BY avg_delay DESC;
```

### Visualizaciones Recomendadas

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar datos
df = pd.read_sql("SELECT * FROM gold.dm.master_table", engine_gold)

# 1. DistribuciÃ³n de retrasos
plt.figure(figsize=(10, 6))
sns.histplot(df['Delayed_time'], bins=50, kde=True)
plt.title('DistribuciÃ³n de Retrasos en Entregas')
plt.xlabel('DÃ­as de Retraso')
plt.ylabel('Frecuencia')
plt.show()

# 2. Real vs Predicho
plt.figure(figsize=(10, 6))
plt.scatter(df['Delayed_time'], df['Delayed_time_predicted'], alpha=0.5)
plt.plot([df['Delayed_time'].min(), df['Delayed_time'].max()], 
         [df['Delayed_time'].min(), df['Delayed_time'].max()], 
         'r--', lw=2)
plt.xlabel('Retraso Real (dÃ­as)')
plt.ylabel('Retraso Predicho (dÃ­as)')
plt.title('PredicciÃ³n vs Realidad')
plt.show()

# 3. Feature Importance
feature_importance = pd.read_csv('/workspace/feature_importance.csv')
top_10 = feature_importance.head(10)
plt.figure(figsize=(10, 6))
sns.barplot(data=top_10, x='importance', y='feature')
plt.title('Top 10 Features MÃ¡s Importantes')
plt.xlabel('Importancia')
plt.show()
```

---

## ğŸ› Troubleshooting

### Error: "No module named 'model_evaluation'"

```bash
# AsegÃºrate de estar en el directorio correcto
cd /Users/howard/Downloads/modulo13/sprint3/olist/src
python gold_fact_sales.py
```

### Error: "Connection refused" (PostgreSQL)

```bash
# Verificar que Docker estÃ© corriendo
docker-compose ps

# Reiniciar servicios
docker-compose restart db
```

### Error: "Out of memory" durante entrenamiento

Reducir el nÃºmero de trials de Optuna:

```python
n_trials=20  # En lugar de 50
```

### Modelo muy lento

- Reducir `n_estimators` en los modelos
- Reducir `cv_folds` de 5 a 3
- Usar menos features en [feature_selection](cci:1://file:///Users/howard/Downloads/modulo13/sprint3/olist/src/gold_fact_sales.py:328:0-483:21)

---

## ğŸ“ Notas Importantes

### Target Variable

- **Delayed_time**: Diferencia en dÃ­as entre entrega real y estimada
- **Rango vÃ¡lido**: -30 a +60 dÃ­as (outliers filtrados)
- **InterpretaciÃ³n**:
  - Negativo: Entrega adelantada
  - Cero: Entrega a tiempo
  - Positivo: Entrega retrasada

### Consideraciones de ProducciÃ³n

1. **Reentrenamiento**: Reentrenar modelo mensualmente con datos nuevos
2. **Monitoreo**: Trackear MAE en producciÃ³n vs entrenamiento
3. **Data Drift**: Verificar distribuciÃ³n de features periÃ³dicamente
4. **Versionado**: Guardar modelos con timestamp en el nombre

---

## ğŸ‘¥ Contribuidores

- **Autor**: Howard
- **Proyecto**: Olist E-Commerce Analytics
- **Fecha**: Noviembre 2025

---

## ğŸ“„ Licencia

Este proyecto es de uso educativo y de investigaciÃ³n.

---

## ğŸ”— Referencias

- [Olist Dataset - Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Prefect Documentation](https://docs.prefect.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)

---

## ğŸ“ Soporte

Para preguntas o issues, contactar al equipo de desarrollo.

**Â¡Happy Modeling! ğŸš€**
# src/flow.py
"""
Flujo Maestro ETL - Arquitectura Medallion
Orquesta la ejecuci√≥n secuencial: Bronze ‚Üí Silver ‚Üí Gold
"""
from prefect import flow, task, get_run_logger
from prefect.task_runners import SequentialTaskRunner
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import os
from dotenv import load_dotenv
from datetime import datetime
from typing import Dict, Any

# Importar flujos de cada capa
from etl_multi import etl_multi_csv
from bronze_to_raw import olist_to_bronze
from silver_curated import bronze_to_silver
from gold_fact_sales import silver_to_gold
from gold_ml_features import build_ml_pipeline

load_dotenv("/workspace/.env")

# Configuraci√≥n de conexiones
CONNECTIONS = {
    "olist": f"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@db:5432/olist",
    "bronze": f"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@db:5432/bronze",
    "silver": f"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@db:5432/silver",
    "gold": f"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@db:5432/gold"
}


@task(name="Validar Conexi√≥n BD", retries=3, retry_delay_seconds=5)
def validate_connection(db_name: str, conn_string: str) -> bool:
    """Valida que la base de datos est√© accesible"""
    logger = get_run_logger()
    
    try:
        engine = create_engine(conn_string)
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1")).scalar()
            logger.info(f"‚úÖ Conexi√≥n exitosa a BD '{db_name}'")
            return True
    except SQLAlchemyError as e:
        logger.error(f"‚ùå Error conectando a '{db_name}': {str(e)}")
        raise
    except Exception as e:
        logger.error(f"‚ùå Error inesperado en '{db_name}': {str(e)}")
        raise


@task(name="Ejecutar Capa con Manejo de Errores")
def execute_layer_safe(layer_name: str, flow_func, **kwargs) -> Dict[str, Any]:
    """
    Ejecuta un flujo de capa con manejo robusto de errores
    
    Args:
        layer_name: Nombre de la capa (Bronze/Silver/Gold)
        flow_func: Funci√≥n del flujo a ejecutar
        **kwargs: Argumentos adicionales para el flujo
    
    Returns:
        Dict con status, timestamp y mensaje
    """
    logger = get_run_logger()
    start_time = datetime.utcnow()
    
    try:
        logger.info(f"üöÄ Iniciando capa: {layer_name}")
        
        # Ejecutar el flujo
        result = flow_func(**kwargs)
        
        end_time = datetime.utcnow()
        duration = (end_time - start_time).total_seconds()
        
        logger.info(f"‚úÖ Capa {layer_name} completada en {duration:.2f}s")
        
        return {
            "layer": layer_name,
            "status": "success",
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration,
            "message": f"Capa {layer_name} ejecutada exitosamente"
        }
        
    except SQLAlchemyError as e:
        logger.error(f"‚ùå Error de base de datos en {layer_name}: {str(e)}")
        return {
            "layer": layer_name,
            "status": "failed",
            "error_type": "SQLAlchemyError",
            "error_message": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except FileNotFoundError as e:
        logger.error(f"‚ùå Archivo no encontrado en {layer_name}: {str(e)}")
        return {
            "layer": layer_name,
            "status": "failed",
            "error_type": "FileNotFoundError",
            "error_message": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error inesperado en {layer_name}: {type(e).__name__} - {str(e)}")
        return {
            "layer": layer_name,
            "status": "failed",
            "error_type": type(e).__name__,
            "error_message": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }


@task(name="Verificar Resultados de Capa")
def verify_layer_results(layer_name: str, result: Dict[str, Any]) -> bool:
    """Verifica si una capa se ejecut√≥ correctamente"""
    logger = get_run_logger()
    
    if result["status"] == "success":
        logger.info(f"‚úÖ Verificaci√≥n exitosa: {layer_name}")
        return True
    else:
        logger.error(f"‚ùå Verificaci√≥n fallida: {layer_name}")
        logger.error(f"   Tipo de error: {result.get('error_type', 'Unknown')}")
        logger.error(f"   Mensaje: {result.get('error_message', 'No message')}")
        return False


@flow(
    name="üèóÔ∏è ETL Maestro - Arquitectura Medallion",
    description="Orquesta la ejecuci√≥n completa: Ingesta ‚Üí Bronze ‚Üí Silver ‚Üí Gold",
    task_runner=SequentialTaskRunner(),
    log_prints=True
)
def master_etl_pipeline(
    skip_ingestion: bool = False,
    skip_bronze: bool = False,
    skip_silver: bool = False,
    skip_gold: bool = False,
    skip_ml: bool = False  # NUEVO
):
    """
    Flujo maestro que ejecuta el pipeline completo ETL
    
    Args:
        skip_ingestion: Si True, omite la carga inicial de CSVs
        skip_bronze: Si True, omite la capa Bronze
        skip_silver: Si True, omite la capa Silver
        skip_gold: Si True, omite la capa Gold
    """
    logger = get_run_logger()
    pipeline_start = datetime.utcnow()
    results = []
    
    logger.info("=" * 80)
    logger.info("üöÄ INICIANDO PIPELINE ETL MAESTRO - ARQUITECTURA MEDALLION")
    logger.info("=" * 80)
    
    try:
        # ============================================================
        # FASE 0: VALIDACI√ìN DE CONEXIONES
        # ============================================================
        logger.info("\nüì° FASE 0: Validando conexiones a bases de datos...")
        
        for db_name, conn_string in CONNECTIONS.items():
            try:
                validate_connection(db_name, conn_string)
            except Exception as e:
                logger.error(f"‚ùå No se pudo conectar a '{db_name}'. Abortando pipeline.")
                raise
        
        logger.info("‚úÖ Todas las conexiones validadas correctamente\n")
        
        # ============================================================
        # FASE 1: INGESTA DE DATOS (CSV ‚Üí BD Olist)
        # ============================================================
        if not skip_ingestion:
            logger.info("üì• FASE 1: Ingesta de datos CSV ‚Üí BD Olist")
            ingestion_result = execute_layer_safe(
                "Ingestion (CSV ‚Üí Olist)",
                etl_multi_csv
            )
            results.append(ingestion_result)
            
            if not verify_layer_results("Ingestion", ingestion_result):
                logger.error("‚ùå Ingesta fall√≥. Abortando pipeline.")
                raise Exception("Fallo en fase de ingesta")
        else:
            logger.info("‚è≠Ô∏è  FASE 1: Ingesta omitida (skip_ingestion=True)\n")
        
        # ============================================================
        # FASE 2: CAPA BRONZE (Olist ‚Üí Bronze.Raw)
        # ============================================================
        if not skip_bronze:
            logger.info("ü•â FASE 2: Capa Bronze (Olist ‚Üí Bronze.Raw)")
            bronze_result = execute_layer_safe(
                "Bronze",
                olist_to_bronze
            )
            results.append(bronze_result)
            
            if not verify_layer_results("Bronze", bronze_result):
                logger.error("‚ùå Capa Bronze fall√≥. Abortando pipeline.")
                raise Exception("Fallo en capa Bronze")
        else:
            logger.info("‚è≠Ô∏è  FASE 2: Capa Bronze omitida (skip_bronze=True)\n")
        
        # ============================================================
        # FASE 3: CAPA SILVER (Bronze ‚Üí Silver.Curated)
        # ============================================================
        if not skip_silver:
            logger.info("ü•à FASE 3: Capa Silver (Bronze ‚Üí Silver.Curated)")
            silver_result = execute_layer_safe(
                "Silver",
                bronze_to_silver
            )
            results.append(silver_result)
            
            if not verify_layer_results("Silver", silver_result):
                logger.error("‚ùå Capa Silver fall√≥. Abortando pipeline.")
                raise Exception("Fallo en capa Silver")
        else:
            logger.info("‚è≠Ô∏è  FASE 3: Capa Silver omitida (skip_silver=True)\n")
        
        # ============================================================
        # FASE 4: CAPA GOLD (Silver ‚Üí Gold.DM)
        # ============================================================
        if not skip_gold:
            logger.info("ü•á FASE 4: Capa Gold (Silver ‚Üí Gold.DM)")
            gold_result = execute_layer_safe(
                "Gold",
                silver_to_gold
            )
            results.append(gold_result)
            
            if not verify_layer_results("Gold", gold_result):
                logger.error("‚ùå Capa Gold fall√≥.")
                raise Exception("Fallo en capa Gold")
        else:
            logger.info("‚è≠Ô∏è  FASE 4: Capa Gold omitida (skip_gold=True)\n")
        
        # ============================================================
        # FASE 5: CAPA GOLD ML (Silver ‚Üí Gold.ML)
        # ============================================================
        if not skip_ml:
            logger.info("ü§ñ FASE 5: Capa Gold ML (Silver ‚Üí Gold.ML Master Table)")
            ml_result = execute_layer_safe(
                "Gold ML",
                build_ml_pipeline
            )
            results.append(ml_result)
            
            if not verify_layer_results("Gold ML", ml_result):
                logger.warning("‚ö†Ô∏è  Capa Gold ML fall√≥ (no cr√≠tico).")
        else:
            logger.info("‚è≠Ô∏è  FASE 5: Capa Gold ML omitida (skip_ml=True)\n")

        # ============================================================
        # RESUMEN FINAL
        # ============================================================
        pipeline_end = datetime.utcnow()
        total_duration = (pipeline_end - pipeline_start).total_seconds()
        
        logger.info("=" * 80)
        logger.info("‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")
        logger.info("=" * 80)
        logger.info(f"‚è±Ô∏è  Duraci√≥n total: {total_duration:.2f} segundos")
        logger.info(f"üìä Capas ejecutadas: {len(results)}")
        
        for result in results:
            status_icon = "‚úÖ" if result["status"] == "success" else "‚ùå"
            logger.info(f"   {status_icon} {result['layer']}: {result['status']}")
        
        logger.info("=" * 80)
        
        return {
            "status": "success",
            "total_duration_seconds": total_duration,
            "layers_executed": len(results),
            "results": results
        }
        
    except Exception as e:
        pipeline_end = datetime.utcnow()
        total_duration = (pipeline_end - pipeline_start).total_seconds()
        
        logger.error("=" * 80)
        logger.error("‚ùå PIPELINE FALL√ì")
        logger.error("=" * 80)
        logger.error(f"‚è±Ô∏è  Duraci√≥n hasta fallo: {total_duration:.2f} segundos")
        logger.error(f"üî• Error: {type(e).__name__} - {str(e)}")
        logger.error("=" * 80)
        
        return {
            "status": "failed",
            "total_duration_seconds": total_duration,
            "error_type": type(e).__name__,
            "error_message": str(e),
            "results": results
        }


@flow(name="ETL ML - Solo Master Table")
def quick_ml_refresh():
    """Flujo r√°pido que solo actualiza la master table ML"""
    logger = get_run_logger()
    logger.info("ü§ñ Ejecutando actualizaci√≥n r√°pida de ML Master Table...")
    
    return master_etl_pipeline(
        skip_ingestion=True,
        skip_bronze=True,
        skip_silver=True,
        skip_gold=True,
        skip_ml=False
    )


if __name__ == "__main__":
    # Ejecutar pipeline completo
    master_etl_pipeline()
